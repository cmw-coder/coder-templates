import os
import re
import json
import asyncio
import threading
import time
import datetime
import subprocess
import pandas as pd
from typing import List, Dict, Any
from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions, AssistantMessage, ResultMessage
import tkinter
from tkinter import messagebox

# åˆ›å»ºéšè—çš„ä¸»çª—å£
root = tkinter.Tk()
root.withdraw()

# --- è¾…åŠ©ç±»ä¸å‡½æ•° ---
# --- è¾…åŠ©ç±»ä¸å‡½æ•° ---
success_check_str = """
+-------+------+------+-------+------+---------+
|   1   |  1   |  0   |   0   |  0   | 100.00% |
+-------+------+------+-------+------+---------+
"""

error_check_str = """
+-------+------+------+-------+------+--------+
|   1   |  0   |  0   |   1   |  0   | 0.00%  |
+-------+------+------+-------+------+--------+
"""

workflow_prompt = r"""
è¯·ä½¿ç”¨ä»¥ä¸‹æ­¥éª¤ä¿®å¤test_netconf.pyä»£ç :
å·¥ä½œæµç¨‹ï¼š
while True:
    æµ‹è¯•æ‰§è¡Œ"D:\\RDTestClientData\\Common\\tools\\Python38\\python.exe" -u -m pytest "å½“å‰æ–‡ä»¶å¤¹ä¸‹çš„test_netconf.pyç»å¯¹è·¯å¾„" --custom-check="{'skip-steps':0}" --testbed="å½“å‰æ–‡ä»¶å¤¹ä¸‹çš„test_bed.tbdxç»å¯¹è·¯å¾„" --script-log-path="å½“å‰æ–‡ä»¶å¤¹è·¯å¾„\log" -s -W ignore::UserWarning -p no:cacheprovider --tb shortï¼Œ ç»“åˆè®¾å¤‡å“åº”æ¶ˆæ¯å’Œå®é™…è¿”å›æŠ¥æ–‡åˆ†ææ§åˆ¶å°æ—¥å¿—ã€‚å‘½ä»¤æ‰§è¡Œçš„æ¯”è¾ƒä¹…ï¼Œå‘½ä»¤æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸è¦åšå…¶ä»–äº‹æƒ…,ç­‰å¾…å‘½ä»¤æ‰§è¡Œå®Œæ¯•ã€‚
    for å¾ªç¯ä¸‰æ¬¡
        è¯†åˆ«ç¬¬ä¸€ä¸ªå¤±è´¥çš„ `test_step` å‡½æ•°ï¼Œæ³¨æ„æ¯æ¬¡åªä¿®å¤ç¬¬ä¸€ä¸ªå¤±è´¥çš„æµ‹è¯•æ­¥éª¤ï¼Œç„¶åå†æ¬¡æ‰§è¡Œå‘½ä»¤
        ç»“åˆå®é™…è¿”å›çš„æŠ¥æ–‡åˆ†æå’Œæ£€æŸ¥é¡¹åˆ†æå¤±è´¥åŸå› ï¼Œæ£€æŸ¥å¤±è´¥æ­¥éª¤ä¸­å‘é€çš„ XML é…ç½®
        ä¸ yin.txtå’Œnetconf.txtä¸­æ¨¡å‹è§„èŒƒè¿›è¡Œæ¯”è¾ƒï¼Œä¸¤è€…å‚æ•°ä¿¡æ¯å†²çªæ—¶ä»¥yin.txtä¸ºä¸»
        ä¿®å¤ XML é…ç½®ä»¥ç¡®ä¿æµ‹è¯•æ­£ç¡®æ‰§è¡Œ
        å¾ªç¯é‡æ–°è¿è¡Œæµ‹è¯•ä»¥éªŒè¯æˆåŠŸ
    
    æ‰§è¡Œå‘½ä»¤ï¼Œæ‰€æœ‰æµ‹è¯•æ­¥éª¤passï¼Œé€€å‡ºå¾ªç¯


**ä¸ºä»€ä¹ˆè¦forå¾ªç¯å†…éƒ¨åªä¿®å¤ç¬¬ä¸€ä¸ªé”™è¯¯çš„æµ‹è¯•æ­¥éª¤ä¸‹å‘çš„xmlï¼Ÿ**
**å›ç­”ï¼šå› ä¸ºæ¯ä¸ªæµ‹è¯•æ­¥éª¤ä¹‹é—´æµ‹è¯•çš„å‚æ•°æ˜¯äº’ç›¸å…³è”çš„ï¼Œåé¢é”™è¯¯çš„æµ‹è¯•ç»“æœå¯èƒ½æ˜¯å‰é¢é”™è¯¯æµ‹è¯•æ­¥éª¤å¯¼è‡´çš„ã€‚æ‰€ä»¥è¦æ¯ä¿®å¤ç¬¬ä¸€ä¸ªé”™è¯¯çš„æµ‹è¯•æ­¥éª¤ï¼Œéƒ½è¦é‡æ–°æ‰§è¡Œå‘½ä»¤ã€‚**
"""

class ThreadSafeLogger:
    # çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—è®°å½•å™¨
    def __init__(self, log_file_path: str):
        self.log_file_path = log_file_path
        self.lock = threading.Lock()
        os.makedirs(os.path.dirname(self.log_file_path), exist_ok=True)

    def log(self, message: str, level: str = "INFO"):
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] [{level}] {message}\n"
        with self.lock:
            with open(self.log_file_path, 'a', encoding='utf-8') as f:
                f.write(log_message)
        print(log_message.strip())

    def error(self, message: str):
        self.log(message, "ERROR")

def run_pytest_and_check(folder_path: str) -> str:
    # æ‰§è¡Œpytestå‘½ä»¤å¹¶è¿”å›å…¶å®Œæ•´çš„è¾“å‡º
    python_path = r"D:\\RDTestClientData\\Common\\tools\\Python38\\python.exe"
    test_script = os.path.join(folder_path, "test_netconf.py")
    test_bed = os.path.join(folder_path, "test_bed.tbdx")
    log_path = os.path.join(folder_path, "log")
    cmd = [python_path, "-u", "-m", "pytest", test_script, '--custom-check={"skip-steps":0}', f"--testbed={test_bed}",
           f"--script-log-path={log_path}", "-s", "-W", "ignore::UserWarning", "-p", "no:cacheprovider", "--tb",
           "short"]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')
        return result.stdout + result.stderr
    except Exception as e:
        error_message = f"æ‰§è¡Œpytestå‘½ä»¤æ—¶å‡ºé”™: {e}"
        print(error_message)
        return error_message

async def run_claude_step(client: ClaudeSDKClient, prompt: str, task_start_time: float, timeout_seconds: int,
                          logger: ThreadSafeLogger) -> Dict[str, Any]:
    # æ‰§è¡Œå•ä¸ªClaudeæ­¥éª¤ï¼ŒåŒ…å«è¶…æ—¶å’Œ429é”™è¯¯é‡è¯•é€»è¾‘
    result_data = {'prompt': prompt, 'success': False, 'error': None, 'cost': 0.0, 'duration': 0.0}
    attempt = 0
    while True:
        attempt += 1
        step_start_time = time.time()
        if time.time() - task_start_time > timeout_seconds:
            result_data['error'] = "ä»»åŠ¡åœ¨APIè°ƒç”¨å‰å·²è¶…æ—¶"
            logger.error(f"ä»»åŠ¡è¶…æ—¶ ({timeout_seconds}ç§’), æ”¾å¼ƒé‡è¯•ã€‚")
            return result_data
        try:
            response_text_parts = []
            logger.log(f"å¼€å§‹Claude APIè°ƒç”¨ (ç¬¬ {attempt} æ¬¡å°è¯•)...")
            await client.query(prompt)
            async for message in client.receive_response():
                if time.time() - task_start_time > timeout_seconds:
                    await client.interrupt()
                    result_data.update({'error': f"æ¥æ”¶å“åº”æ—¶è¶…æ—¶ ({timeout_seconds}ç§’)", 'success': False})
                    return result_data
                if isinstance(message, AssistantMessage):
                    response_text_parts.extend(block.text for block in message.content if hasattr(block, 'text'))
                elif isinstance(message, ResultMessage):
                    result_data.update({'cost': message.total_cost_usd, 'success': not message.is_error,
                                        'error': message.result if message.is_error else None})
                    break
            result_data['duration'] = time.time() - step_start_time
            result_data['analysis'] = ''.join(response_text_parts)
            if result_data['success']:
                logger.log(f"Claude APIè°ƒç”¨æˆåŠŸ (å°è¯•æ¬¡æ•°: {attempt}).")
                return result_data
            else:
                logger.error(f"Claude APIè¿”å›é€»è¾‘é”™è¯¯: {result_data.get('error')}")
                return result_data
        except Exception as e:
            error_str = str(e)
            logger.log(f"Claude APIè°ƒç”¨å¤±è´¥ (å°è¯•æ¬¡æ•°: {attempt}): {error_str}", "WARNING")
            result_data['error'] = error_str
            if "API Error: 429" in error_str:
                wait_seconds = 60
                match = re.search(r'limit will reset at (\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', error_str)
                if match:
                    reset_time = datetime.datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S')
                    wait_seconds = max(2, (reset_time - datetime.datetime.now()).total_seconds() + 2)
                if (time.time() + wait_seconds) > (task_start_time + timeout_seconds):
                    logger.error("ç­‰å¾…æ—¶é—´å°†å¯¼è‡´ä»»åŠ¡è¶…æ—¶ï¼Œæ”¾å¼ƒé‡è¯•ã€‚")
                    return result_data
                logger.log(f"è§¦å‘APIé€Ÿç‡é™åˆ¶ã€‚ç­‰å¾… {wait_seconds:.0f} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_seconds)
                continue
            else:
                logger.error("å‘ç”Ÿä¸å¯æ¢å¤çš„é”™è¯¯ï¼Œä¸å†é‡è¯•ã€‚")
                return result_data

def excel_to_json(excel_filename: str, json_filename: str) -> bool:
    """å°†æ—§ExcelæŠ¥å‘Šè½¬æ¢ä¸ºJSONæ ¼å¼ï¼Œè¿”å›è½¬æ¢æ˜¯å¦æˆåŠŸ"""
    print(f"\nğŸ”„ æ£€æµ‹åˆ°æ—§ExcelæŠ¥å‘Šï¼š{excel_filename}ï¼Œå¼€å§‹è½¬æ¢ä¸ºJSON...")
    try:
        # è¯»å–Excelæ–‡ä»¶
        df = pd.read_excel(excel_filename, engine='openpyxl')
        
        # éªŒè¯å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['Folder', 'Step Name', 'Success', 'Cost ($)', 'Duration (s)', 'Error', 'Prompt', 'Claude Analysis']
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            print(f"âŒ Excelæ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}ï¼Œè½¬æ¢å¤±è´¥")
            return False
        
        # å¡«å……ç¼ºå¤±å€¼ï¼Œç¡®ä¿æ•°æ®æ ¼å¼ç»Ÿä¸€
        df = df.fillna({
            'Cost ($)': 0.0,
            'Duration (s)': 0.0,
            'Error': '',
            'Prompt': '',
            'Claude Analysis': ''
        })
        
        # è½¬æ¢ä¸ºJSONæ ¼å¼ï¼ˆæ·»åŠ Last Updatedå­—æ®µï¼‰
        json_data = []
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        for _, row in df.iterrows():
            json_data.append({
                'Folder': str(row['Folder']),
                'Step Name': str(row['Step Name']),
                'Success': bool(row['Success']),
                'Cost ($)': round(float(row['Cost ($)']), 4),
                'Duration (s)': round(float(row['Duration (s)']), 2),
                'Error': str(row['Error']),
                'Prompt': str(row['Prompt']),
                'Claude Analysis': str(row['Claude Analysis']),
                'Last Updated': current_time  # è½¬æ¢æ—¶ç»Ÿä¸€è®¾ç½®ä¸ºå½“å‰æ—¶é—´
            })
        
        # ä¿å­˜ä¸ºJSONæ–‡ä»¶
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Excelè½¬JSONæˆåŠŸï¼ç”Ÿæˆæ–‡ä»¶ï¼š{json_filename}")
        return True
    except Exception as e:
        print(f"âŒ Excelè½¬JSONå¤±è´¥ï¼š{str(e)}")
        return False

def load_existing_json(json_filename: str) -> List[Dict[str, Any]]:
    """åŠ è½½å·²å­˜åœ¨çš„JSONæŠ¥å‘Šï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›ç©ºåˆ—è¡¨"""
    if not os.path.exists(json_filename):
        return []
    try:
        with open(json_filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # éªŒè¯æ•°æ®æ ¼å¼æ˜¯å¦ä¸ºåˆ—è¡¨
            if isinstance(data, list):
                return data
            else:
                print(f"âš ï¸ JSONæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ˆåº”ä¸ºåˆ—è¡¨ï¼‰ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶ã€‚")
                return []
    except json.JSONDecodeError as e:
        print(f"âš ï¸ è§£æJSONæ–‡ä»¶å¤±è´¥ï¼š{e}ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶ã€‚")
        return []
    except Exception as e:
        print(f"âš ï¸ è¯»å–JSONæ–‡ä»¶å¤±è´¥ï¼š{e}ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶ã€‚")
        return []

async def update_json(result: Dict[str, Any], json_filename: str, lock: asyncio.Lock):
    """å®‰å…¨åœ°æ›´æ–°æˆ–è¿½åŠ ç»“æœåˆ°JSONæ–‡ä»¶ï¼ˆä¿ç•™åŸæœ‰æ•°æ®ï¼‰"""
    if not isinstance(result, dict) or 'folder' not in result:
        return

    folder_name = result['folder']
    records = []

    # æ„å»ºæ–°è®°å½•ï¼ˆä¿æŒä¸åŸExcelåˆ—å¯¹åº”çš„å­—æ®µï¼‰
    if not result.get('step_results'):
        records.append({
            'Folder': folder_name,
            'Step Name': 'Initialization',
            'Success': result.get('success', False),
            'Cost ($)': 0.0,
            'Duration (s)': 0.0,
            'Error': result.get('error', 'No steps executed'),
            'Prompt': '',
            'Claude Analysis': '',
            'Last Updated': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })
    else:
        for step_res in result['step_results']:
            records.append({
                'Folder': folder_name,
                'Step Name': step_res.get('step_name', ''),
                'Success': step_res.get('success', False),
                'Cost ($)': round(step_res.get('cost', 0.0), 4),
                'Duration (s)': round(step_res.get('duration', 0.0), 2),
                'Error': step_res.get('error') or '',
                'Prompt': step_res.get('prompt') or '',
                'Claude Analysis': step_res.get('analysis') or '',
                'Last Updated': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })

    async with lock:
        try:
            # åŠ è½½ç°æœ‰æ•°æ®
            existing_data = load_existing_json(json_filename)
            
            # è¿‡æ»¤æ‰å½“å‰æ–‡ä»¶å¤¹çš„æ—§è®°å½•ï¼ˆä¿ç•™å…¶ä»–æ–‡ä»¶å¤¹æ•°æ®ï¼‰
            updated_data = [item for item in existing_data if item.get('Folder') != folder_name]
            
            # è¿½åŠ æ–°è®°å½•
            updated_data.extend(records)
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶ï¼ˆæ ¼å¼åŒ–è¾“å‡ºï¼Œä¾¿äºé˜…è¯»ï¼‰
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(updated_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ å·²å°† '{folder_name}' çš„è®°å½• {'æ›´æ–°' if any(item.get('Folder') == folder_name for item in existing_data) else 'è¿½åŠ '} åˆ°JSONã€‚")
        except Exception as e:
            print(f"âŒ ä¿å­˜ '{folder_name}' çš„è®°å½•åˆ°JSONå¤±è´¥: {e}")

def generate_summary_report(results: List[Dict[str, Any]], total_time: float, report_title: str):
    # ç”Ÿæˆæœ€ç»ˆçš„æ§åˆ¶å°æ±‡æ€»æŠ¥å‘Š
    successful = [r for r in results if isinstance(r, dict) and r.get('success')]
    total_cost = sum(r.get('total_cost', 0.0) for r in results if isinstance(r, dict))
    print("\n" + "=" * 60 + f"\nğŸ“Š {report_title} æ±‡æ€»æŠ¥å‘Š\n" + "=" * 60)
    print(f"ğŸ“ æ€»ä»»åŠ¡æ•°: {len(results)}")
    print(f"âœ… æˆåŠŸ: {len(successful)}")
    print(f"âŒ å¤±è´¥: {len(results) - len(successful)}")
    print(f"ğŸ’° æ€»æˆæœ¬: ${total_cost:.4f}")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time / 60:.2f} åˆ†é’Ÿ)")
    print("=" * 60)

# --- æ ¸å¿ƒå¤„ç†é€»è¾‘ ---
async def process_new_folder(folder_path: str, logger: ThreadSafeLogger, timeout_minutes: int) -> Dict[str, Any]:
    """å¤„ç†æ–°æ–‡ä»¶å¤¹ï¼šå®Œæ•´æµç¨‹ï¼ˆpytestæ£€æŸ¥ + å¯èƒ½çš„Claudeä¿®å¤ + æœ€ç»ˆéªŒè¯ï¼‰"""
    task_start_time = time.time()
    folder_name = os.path.basename(folder_path)
    result = {'folder': folder_name, 'success': False, 'step_results': [], 'total_cost': 0.0, 'total_duration': 0.0}

    try:
        logger.log(f"å¼€å§‹å®Œæ•´æµç¨‹ï¼špytestæ£€æŸ¥ + å¯èƒ½çš„Claudeä¿®å¤ï¼ˆæ€»è¶…æ—¶ï¼š{timeout_minutes}åˆ†é’Ÿï¼‰")

        test_script = os.path.join(folder_path, "test_netconf.py")
        if not os.path.exists(test_script) or  "test_step_2" not in open(test_script, "r", errors="ignore").read():
            logger.log("ä»£ç æœªè¡¥å…¨ï¼Œè·³è¿‡å®Œæ•´æµç¨‹ã€‚")
            raise Exception("ä»£ç æœªè¡¥å…¨ï¼Œæ— æ³•æ‰§è¡Œå®Œæ•´æµç¨‹")

        # æ­¥éª¤1ï¼šé¦–æ¬¡è¿é€šæ€§æ£€æŸ¥
        logger.log("æ­¥éª¤1/3ï¼šé¦–æ¬¡è¿é€šæ€§æ£€æŸ¥...")
        initial_log = run_pytest_and_check(folder_path)
        log_file_path = os.path.join(folder_path, "pytest_initial_log.txt")
        with open(log_file_path, "w", encoding='utf-8') as f:
            f.write(initial_log)
        

        if success_check_str in initial_log:
            logger.log("âœ… é¦–æ¬¡æ£€æŸ¥é€šè¿‡ï¼Œæ— éœ€ä¿®å¤")
            result['success'] = True
            step_result = {
                'step_name': 'Initial_Check',
                'success': True,
                'cost': 0.0,
                'duration': time.time() - task_start_time,
                'error': None,
                'prompt': '',
                'analysis': 'é¦–æ¬¡æ£€æŸ¥é€šè¿‡ï¼Œä»£ç æ— éœ€ä¿®å¤'
            }
            result['step_results'].append(step_result)
        elif error_check_str in initial_log:
            logger.log("âš ï¸  æ£€æµ‹åˆ°DUT1è¿æ¥é”™è¯¯ï¼Œéœ€æ‰‹åŠ¨å¹²é¢„")
            result['success'] = False
            result['error'] = "DUT1è®¾å¤‡è¿æ¥é”™è¯¯ï¼ˆéœ€æ‰‹åŠ¨æ£€æŸ¥ï¼‰"
            step_result = {
                'step_name': 'Initial_Check',
                'success': False,
                'cost': 0.0,
                'duration': time.time() - task_start_time,
                'error': result['error'],
                'prompt': '',
                'analysis': 'é¦–æ¬¡æ£€æŸ¥å‘ç°DUT1è¿æ¥é”™è¯¯'
            }
            result['step_results'].append(step_result)
        else:
            # æ­¥éª¤2ï¼šè°ƒç”¨Claudeä¿®å¤
            logger.log("æ­¥éª¤2/3ï¼šè°ƒç”¨Claudeä¿®å¤ä»£ç ...")
            options = ClaudeAgentOptions(
                system_prompt={"type": "preset", "preset": "claude_code"},
                allowed_tools=["Bash", "Edit", "Glob", "Grep", "Read", "Write"],
                permission_mode="bypassPermissions",
                cwd=folder_path
            )
            async with ClaudeSDKClient(options=options) as client:
                prompt = workflow_prompt
                debug_res = await run_claude_step(client, prompt, task_start_time, timeout_minutes * 60, logger)
            debug_res['step_name'] = 'CodeDebugging_Attempt'
            result['step_results'].append(debug_res)

            if not debug_res.get('success'):
                raise Exception(f"Claudeä¿®å¤å¤±è´¥ï¼š{debug_res.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # æ­¥éª¤3ï¼šæœ€ç»ˆéªŒè¯
            logger.log("æ­¥éª¤3/3ï¼šæœ€ç»ˆéªŒè¯æ£€æŸ¥...")
            final_log = run_pytest_and_check(folder_path)
            log_file_path_final = os.path.join(folder_path, "pytest_final_log.txt")
            with open(log_file_path_final, "w", encoding='utf-8') as f:
                f.write(final_log)

            if success_check_str in final_log:
                logger.log("âœ… æœ€ç»ˆéªŒè¯é€šè¿‡ï¼Œä»£ç ä¿®å¤æˆåŠŸ")
                result['success'] = True
                verify_result = {
                    'step_name': 'Final_Verification',
                    'success': True,
                    'cost': 0.0,
                    'duration': time.time() - task_start_time - sum(r.get('duration', 0.0) for r in result['step_results']),
                    'error': None,
                    'prompt': '',
                    'analysis': 'æœ€ç»ˆéªŒè¯é€šè¿‡ï¼Œä¿®å¤åçš„ä»£ç å¯æ­£å¸¸è¿è¡Œ'
                }
                result['step_results'].append(verify_result)
            else:
                result['error'] = "ä»£ç ä¿®å¤å¤±è´¥ï¼Œæœ€ç»ˆéªŒè¯æœªé€šè¿‡"
                logger.error(result['error'])
                verify_result = {
                    'step_name': 'Final_Verification',
                    'success': False,
                    'cost': 0.0,
                    'duration': time.time() - task_start_time - sum(r.get('duration', 0.0) for r in result['step_results']),
                    'error': result['error'],
                    'prompt': '',
                    'analysis': f'æœ€ç»ˆéªŒè¯å¤±è´¥\npytestæ—¥å¿—ç‰‡æ®µï¼š{final_log[:500]}...'
                }
                result['step_results'].append(verify_result)

    except Exception as e:
        result['error'] = str(e)
        logger.error(f"å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥ï¼š{e}")

    result['total_duration'] = time.time() - task_start_time
    result['total_cost'] = sum(r.get('cost', 0.0) for r in result['step_results'])
    return result

async def main():
    # ä¸»å‡½æ•°
    destination_folder = r"D:\yang\B75_yin\generated_modules"
    folders_to_process = [f.path for f in os.scandir(destination_folder) if f.is_dir() and f.name.endswith('_debug')]

    if not folders_to_process:
        print("âŒ æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„ '_debug' æ–‡ä»¶å¤¹ã€‚")
        return

    # é…ç½®å‚æ•°
    max_concurrent = 1
    timeout_minutes = 120
    # excel_filename = os. path.join(destination_folder, "2_debugging_report.xlsx")  # æ—§ExcelæŠ¥å‘Šè·¯å¾„
    json_filename = os.path.join(destination_folder, "2_debugging_report.json")  # æ–°JSONæŠ¥å‘Šè·¯å¾„
    json_lock = asyncio.Lock()

    # # --- Excelè½¬JSONé€»è¾‘ ---
    # if os.path.exists(excel_filename) and not os.path.exists(json_filename):
    #     # å­˜åœ¨æ—§Excelä½†æ— JSONï¼Œæ‰§è¡Œè½¬æ¢
    #     convert_success = excel_to_json(excel_filename, json_filename)
    #     if convert_success:
    #         # è¯¢é—®æ˜¯å¦åˆ é™¤æ—§Excelæ–‡ä»¶
    #         delete_excel = messagebox.askyesno("åˆ é™¤æ—§Excel", "Excelè½¬JSONå·²å®Œæˆï¼Œæ˜¯å¦åˆ é™¤åŸExcelæ–‡ä»¶ï¼Ÿ\nï¼ˆå»ºè®®å¤‡ä»½ååˆ é™¤ï¼Œé¿å…åç»­æ··æ·†ï¼‰")
    #         if delete_excel:
    #             try:
    #                 os.remove(excel_filename)
    #                 print(f"ğŸ—‘ï¸  å·²åˆ é™¤æ—§Excelæ–‡ä»¶ï¼š{excel_filename}")
    #             except Exception as e:
    #                 print(f"âŒ åˆ é™¤æ—§Excelæ–‡ä»¶å¤±è´¥ï¼š{e}")
    #     else:
    #         print("âš ï¸ Excelè½¬JSONå¤±è´¥ï¼Œå°†åˆ›å»ºæ–°çš„JSONæŠ¥å‘Šï¼ˆæ—§Excelæ•°æ®æœªè¿ç§»ï¼‰")
    # elif os.path.exists(excel_filename) and os.path.exists(json_filename):
    #     # åŒæ—¶å­˜åœ¨Excelå’ŒJSONï¼Œæç¤ºç”¨æˆ·é€‰æ‹©
    #     choice = messagebox.askquestion("æŠ¥å‘Šæ–‡ä»¶å†²çª", "å·²åŒæ—¶å­˜åœ¨Excelå’ŒJSONæŠ¥å‘Šæ–‡ä»¶ï¼\næ˜¯å¦ä»¥JSONä¸ºå‡†ç»§ç»­ï¼Ÿï¼ˆExcelæ–‡ä»¶å°†ä¿ç•™ï¼Œä¸å½±å“ï¼‰")
    #     if choice != 'yes':
    #         print("âŒ ç”¨æˆ·é€‰æ‹©ä¸ä»¥JSONä¸ºå‡†ï¼Œç¨‹åºé€€å‡ºã€‚")
    #         return
    #     else:
    #         print("âœ… ç”¨æˆ·é€‰æ‹©ä»¥JSONä¸ºå‡†ï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡ã€‚")

    # åŠ è½½ç°æœ‰JSONæ•°æ®ï¼Œåˆ¤æ–­å“ªäº›æ–‡ä»¶å¤¹å·²å­˜åœ¨
    existing_data = load_existing_json(json_filename)
    existing_folders = set(item.get('Folder') for item in existing_data if item.get('Folder'))
    
    # ç­›é€‰ï¼šä»…ä¿ç•™JSONä¸­ä¸å­˜åœ¨çš„æ–‡ä»¶å¤¹ï¼ˆå·²å­˜åœ¨çš„ç›´æ¥è·³è¿‡ï¼Œä¿ç•™åŸæœ‰æ•°æ®ï¼‰
    new_folders = [f for f in folders_to_process if os.path.basename(f) not in existing_folders]
    skipped_folders = [os.path.basename(f) for f in folders_to_process if os.path.basename(f) in existing_folders]
    
    # æ˜¾ç¤ºä»»åŠ¡ä¿¡æ¯
    print(f"\nğŸ“‹ ä»»åŠ¡æ¦‚å†µï¼š")
    print(f"   å¾…å¤„ç†æ–‡ä»¶å¤¹æ€»æ•°ï¼š{len(folders_to_process)}")
    print(f"   å·²å­˜åœ¨äºJSONæŠ¥å‘Šï¼Œè·³è¿‡çš„æ–‡ä»¶å¤¹æ•°ï¼š{len(skipped_folders)}")
    if skipped_folders:
        print(f"   è·³è¿‡çš„æ–‡ä»¶å¤¹ï¼š{', '.join(skipped_folders)}")
    print(f"   æ–°å¢å¾…å¤„ç†æ–‡ä»¶å¤¹æ•°ï¼š{len(new_folders)}")
    print(f"   å•ä¸ªä»»åŠ¡è¶…æ—¶ï¼š{timeout_minutes} åˆ†é’Ÿ")
    print(f"   å¹¶å‘æ•°ï¼š{max_concurrent}")
    print(f"   æŠ¥å‘Šæ–‡ä»¶ï¼š{json_filename}")
    
    if not new_folders:
        print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤¹å‡å·²å­˜åœ¨äºJSONæŠ¥å‘Šä¸­ï¼Œæ— éœ€å¤„ç†ï¼")
        return
    
    start_time = time.time()
    semaphore = asyncio.Semaphore(max_concurrent)
    tasks = []

    # å®šä¹‰å¸¦å¹¶å‘æ§åˆ¶çš„ä»»åŠ¡æ‰§è¡Œå‡½æ•°
    async def run_task(folder_path):
        async with semaphore:
            folder_name = os.path.basename(folder_path)
            # åˆå§‹åŒ–æ—¥å¿—å™¨
            log_file = os.path.join(folder_path, "process_log.txt")
            if os.path.exists(log_file):
                os.remove(log_file)
            logger = ThreadSafeLogger(log_file)

            # ä»…æ‰§è¡Œæ–°æ–‡ä»¶å¤¹çš„å®Œæ•´å¤„ç†æµç¨‹
            result = await process_new_folder(folder_path, logger, timeout_minutes)

            # æ›´æ–°JSONï¼ˆè¿½åŠ æ–°è®°å½•ï¼Œä¿ç•™åŸæœ‰æ•°æ®ï¼‰
            await update_json(result, json_filename, json_lock)
            return result

    # ä¸ºæ–°å¢æ–‡ä»¶å¤¹åˆ›å»ºä»»åŠ¡
    for folder in new_folders:
        tasks.append(run_task(folder))

    # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # æ•´ç†ç»“æœï¼ˆè¿‡æ»¤å¼‚å¸¸ï¼‰
    final_results = []
    for res in results:
        if isinstance(res, Exception):
            error_msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ï¼š{str(res)}"
            print(f"âŒ {error_msg}")
            final_results.append({'success': False, 'error': error_msg, 'folder': 'æœªçŸ¥æ–‡ä»¶å¤¹', 'total_cost': 0.0})
        else:
            final_results.append(res)

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    total_time = time.time() - start_time
    generate_summary_report(final_results, total_time, "ä»£ç è°ƒè¯•ï¼ˆä»…æ–°å¢æ–‡ä»¶å¤¹ï¼‰")
    print(f"\nğŸ‰ æ‰€æœ‰æ–°å¢æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼æœ€ç»ˆæŠ¥å‘Šï¼š{json_filename}")
    print(f"ğŸ“Œ æç¤ºï¼šå·²ä¿ç•™JSONä¸­åŸæœ‰æ–‡ä»¶å¤¹çš„å†å²æ•°æ®ï¼Œä»…è¿½åŠ æ–°å¢æ–‡ä»¶å¤¹çš„å¤„ç†è®°å½•")
    print(f"ğŸ“Œ JSONæ–‡ä»¶æ”¯æŒç›´æ¥ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ï¼Œæˆ–å¯¼å…¥å…¶ä»–å·¥å…·è¿›è¡Œåˆ†æ")

if __name__ == "__main__":
    # ç¯å¢ƒå˜é‡é…ç½®
    os.environ['ANTHROPIC_BASE_URL'] = 'https://open.bigmodel.cn/api/anthropic'
    os.environ['ANTHROPIC_AUTH_TOKEN'] = 'eb8424b62e54473491ec97f32bbccee6.Oz7nZBCmYoqsu1o2'
    os.environ["API_TIMEOUT_MS"] = "7200000"  # ä¸timeout_minutesä¿æŒä¸€è‡´ï¼ˆ120åˆ†é’Ÿï¼‰
    os.environ["CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC"] = "1"

    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())